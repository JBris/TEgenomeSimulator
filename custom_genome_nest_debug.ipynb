{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a155af4-2d42-4e60-9675-5ab0826ef48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import yaml\n",
    "import re\n",
    "from Bio import SeqIO, Seq\n",
    "from pathlib import Path\n",
    "from custom_genome_seq_TEs import parse_random_genome_yaml, parse_custom_genome_yaml, load_repeats_chr, generate_mismatches, add_indels, add_base_changes\n",
    "from custom_genome_seq_TEs import get_identity, create_TSD, fragment\n",
    "#from random_sequence_TEs import load_repeats, generate_mismatches, add_indels, add_base_changes\n",
    "#from random_sequence_TEs import get_identity, create_TSD, fragment\n",
    "\n",
    "#Load params from YAML file config.yml in same directory\n",
    "def parse_yaml():\n",
    "    params = yaml.load(open('config.yml', 'r'), Loader=yaml.FullLoader)\n",
    "    return params\n",
    "\n",
    "#Turn gff table into a big list where each item represent a row in gff table\n",
    "def load_gff(gff_file):\n",
    "    gff = []\n",
    "    with open(gff_file) as gff_fh:\n",
    "        for i in gff_fh:\n",
    "            e = i.strip().split(\"\\t\")\n",
    "            gff.append(e)\n",
    "    return gff\n",
    "\n",
    "#Modify the coordinates of TE loci locating downstream of the nested insertion \n",
    "def modify_coords(offset, index, new_gff):\n",
    "    new_gff_aux = []\n",
    "    for i in range(index, len(new_gff)):\n",
    "            start = int(new_gff[i][3]) + offset\n",
    "            new_gff[i][3] = str(start)\n",
    "            end = int(new_gff[i][4]) + offset\n",
    "            new_gff[i][4] = str(end)\n",
    "    return new_gff\n",
    "\n",
    "def filter_nonest(gff):\n",
    "    c = 0\n",
    "    vec_cand = []\n",
    "    for i in gff:\n",
    "        if \"Alu\" in i[8] or \"SINE\" in i[8]:\n",
    "            pass\n",
    "        else:\n",
    "            vec_cand.append(c)\n",
    "        c+=1\n",
    "    return vec_cand\n",
    "\n",
    "#Turn the inserted repeat fasta file into a dictionary with te_id as key (function created by THC)\n",
    "def load_isrt_te_fa(inserted_te_fasta_file):\n",
    "    isrt_te_dict=SeqIO.to_dict(SeqIO.parse(inserted_te_fasta_file,\"fasta\"))    \n",
    "    keys_copy = list(isrt_te_dict.keys())\n",
    "    for key in keys_copy:\n",
    "        new_key = re.sub(\".*_TE\", \"TE\", key)\n",
    "        new_key = re.sub(\"#.*\",\"\", new_key)\n",
    "        isrt_te_dict[new_key] = isrt_te_dict.pop(key)    \n",
    "    return isrt_te_dict\n",
    "\n",
    "#Generate vector of coords for base_changes and indels\n",
    "def generate_nests(repeats, gff, seq, prefix):\n",
    "    rep_count = []\n",
    "    new_seq = \"\"\n",
    "    #Create a list containing the TE family and the required copies for nested insertion\n",
    "    for i in repeats:\n",
    "        rep_count += [i]*int(repeats[i].num_rep*(repeats[i].nest/100.0))\n",
    "    #Shuffle the list\n",
    "    random.shuffle(rep_count)\n",
    "    #Acquire the index of TEs from gff file (excluding Alu and SINE)\n",
    "    vec_cand = filter_nonest(gff)\n",
    "    #Randomly pick the index of TE loci to be inserted with nested TEs\n",
    "    #insert_index = random.sample(range(0, len(gff)-1), len(rep_count))\n",
    "    insert_index = random.sample(vec_cand, len(rep_count))\n",
    "    new_gff = gff\n",
    "    sorted_table = sorted(zip(insert_index, rep_count))\n",
    "    counter = 0\n",
    "    n = 0\n",
    "    for j,k in zip(sorted_table, rep_count):\n",
    "        gff_sel = new_gff[j[0] + counter]\n",
    "        start = int(gff_sel[3])\n",
    "        end = int(gff_sel[4])\n",
    "        length = end - start +1\n",
    "        \n",
    "        #Decide on the position of nested insertion in association to the length of host TE locus \n",
    "        pct_pos = random.randint(40,60)\n",
    "        ins_pos = int(round((pct_pos/100.0) * length))\n",
    "        \n",
    "        #Create SNPs, indels and TSD for the nested TE\n",
    "        nest_seq = repeats[k].sequence\n",
    "        nest_identity = get_identity(repeats[k].identity, repeats[k].sd)\n",
    "        nest_identity_fix = nest_identity + (100 - nest_identity) * 0.5\n",
    "        nest_indels = repeats[k].indels\n",
    "        base_changes_vec, indels_changes_vec = generate_mismatches(nest_seq, nest_identity_fix, nest_indels)\n",
    "        nest_seq_mismatches = add_base_changes(nest_seq, base_changes_vec)\n",
    "        new_nest_seq = add_indels(nest_seq_mismatches, indels_changes_vec)\n",
    "\n",
    "        new_nest_seq_tsd = new_nest_seq\n",
    "        tsd_5_len = tsd_3_len = 0\n",
    "        if repeats[k].tsd:\n",
    "            tsd_seq_5, tsd_seq_3 = create_TSD(nest_identity_fix, nest_indels)\n",
    "            new_nest_seq_tsd = tsd_seq_5 + new_nest_seq + tsd_seq_3\n",
    "            tsd_5_len = len(tsd_seq_5)\n",
    "            tsd_3_len = len(tsd_seq_3)\n",
    "\n",
    "        #Fragment weighted (applying two-third chance of fragmentation)\n",
    "        isFrag = random.choice([1,1,0])\n",
    "        new_nest_seq_tsd_frag = new_nest_seq_tsd\n",
    "        if isFrag:\n",
    "            new_nest_seq_tsd_frag, frag, cut = fragment(new_nest_seq_tsd)\n",
    "\n",
    "        nest_len = len(new_nest_seq_tsd_frag)\n",
    "        nest_name = repeats[k].name\n",
    "\n",
    "        #Calculate the coordinates of the host TEs and nested TEs after insertion\n",
    "        new_end_1 = start + ins_pos\n",
    "        new_start_2 = new_end_1 + nest_len \n",
    "        new_end_2 = new_start_2 + (length - ins_pos)\n",
    "\n",
    "        #Apply strand sense\n",
    "        strands = [\"+\", \"-\"]\n",
    "        strand = random.choice(strands)\n",
    "        new_nest_seq_str = new_nest_seq_tsd_frag\n",
    "        \n",
    "        if strand == \"-\":\n",
    "            new_nest_seq_str = str(Seq.Seq(new_nest_seq_tsd_frag).reverse_complement())\n",
    "\n",
    "        #Prepare updated content to be put into gff list    \n",
    "        frag_note = \"\"\n",
    "        if isFrag:\n",
    "            frag_note = \";fragment=\" + str(frag)\n",
    "        ori_name_1 = [gff_sel[8].replace(\";ide\",\"_1;ide\") + \";note=cut_\" + str(pct_pos)]\n",
    "        ori_line_1 = gff_sel[:3] + [start] + [new_end_1] + gff_sel[5:8] + ori_name_1\n",
    "\n",
    "        nest_name_in = [\"ID=\" + nest_name + \"_n\" + str(n) + \";identity=\" + str(nest_identity) + \";note=nested\" + frag_note ]\n",
    "        nested_line = gff_sel[:3] + [new_end_1+1+tsd_5_len] + [new_start_2-tsd_3_len] + [\".\\t\" + strand + \"\\t.\"] + nest_name_in\n",
    "        \n",
    "        ori_name_2 = [gff_sel[8].replace(\";ide\",\"_2;ide\") + \";note=cut_\" + str(100-pct_pos)]\n",
    "        ori_line_2 = gff_sel[:3] + [new_start_2] + [new_end_2 -1] + gff_sel[5:8] + ori_name_2\n",
    "        \n",
    "        n += 1\n",
    "        \n",
    "        #Update the entire gff list\n",
    "        index = j[0] + counter\n",
    "        new_gff.pop(index)\n",
    "        new_gff_aux = new_gff[:index]\n",
    "        new_gff_aux.append(ori_line_1)\n",
    "        new_gff_aux.append(nested_line)\n",
    "        new_gff_aux.append(ori_line_2)\n",
    "        new_gff_aux += new_gff[index:]\n",
    "        new_gff = new_gff_aux\n",
    "        new_gff = modify_coords(nest_len, index+3, new_gff)\n",
    "        counter += 2\n",
    "        \n",
    "        #Update the genome sequence\n",
    "        new_seq = seq[:new_end_1] + new_nest_seq_str + seq[new_end_1:] \n",
    "        seq = new_seq\n",
    "    #Output fasta files of the genome, repeats and the gff file\n",
    "    print_data(prefix, seq, new_gff)\n",
    "\n",
    "#Generate genome with nested insertions (function created by THC)\n",
    "def generate_genome_nests(repeats, isrt_te_dict, gff, genome):\n",
    "    rep_count = []\n",
    "    new_seq = \"\"\n",
    "    nest_te_dict = {}\n",
    "    \n",
    "    #Create a list containing the TE family and the required copies for nested insertion\n",
    "    for i in repeats:\n",
    "        rep_count += [i]*int(repeats[i].num_rep*(repeats[i].nest/100.0))\n",
    "    \n",
    "    #Acquire the index of TEs from gff file (excluding Alu and SINE)\n",
    "    vec_cand = filter_nonest(gff)\n",
    "    \n",
    "    #Randomly pick the index of TE loci to be inserted with nested TEs\n",
    "    insert_index = random.sample(vec_cand, len(rep_count))\n",
    "    \n",
    "    new_gff = gff\n",
    "    sorted_table = sorted(zip(insert_index, rep_count))\n",
    "    counter = 0\n",
    "    n = 1\n",
    "    \n",
    "    for j,k in zip(sorted_table, rep_count):\n",
    "        gff_sel = new_gff[j[0] + counter]\n",
    "        start = int(gff_sel[3])\n",
    "        end = int(gff_sel[4])\n",
    "        length = end - start +1\n",
    "        \n",
    "        #Decide on the position of nested insertion in association to the length of host TE locus \n",
    "        pct_pos = random.randint(40,60)\n",
    "        ins_pos = int(round((pct_pos/100.0) * length))\n",
    "                        \n",
    "        #Get family name, subclass and superfamily of nested TE\n",
    "        nest_name = repeats[k].name\n",
    "        nest_subclas = repeats[k].subclass\n",
    "        nest_superfam = repeats[k].superfamily \n",
    "        \n",
    "        #Create SNPs, indels and TSD for the nested TE\n",
    "        nest_seq = repeats[k].sequence\n",
    "        nest_identity = get_identity(repeats[k].identity, repeats[k].sd)\n",
    "        nest_identity_fix = nest_identity + (100 - nest_identity) * 0.5\n",
    "        nest_indels = repeats[k].indels\n",
    "        base_changes_vec, indels_changes_vec = generate_mismatches(nest_seq, nest_identity_fix, nest_indels)\n",
    "        nest_seq_mismatches = add_base_changes(nest_seq, base_changes_vec)\n",
    "        new_nest_seq = add_indels(nest_seq_mismatches, indels_changes_vec)\n",
    "        \n",
    "        new_nest_seq_tsd = new_nest_seq\n",
    "        tsd_5_len = tsd_3_len = 0\n",
    "        if repeats[k].tsd != [0, 0]:\n",
    "            TSD_min = repeats[k].tsd[0]\n",
    "            TSD_max = repeats[k].tsd[1]\n",
    "            tsd_seq_5, tsd_seq_3 = create_TSD(TSD_min, TSD_max, nest_identity_fix, nest_indels)\n",
    "            new_nest_seq_tsd = tsd_seq_5 + new_nest_seq + tsd_seq_3\n",
    "            tsd_5_len = len(tsd_seq_5)\n",
    "            tsd_3_len = len(tsd_seq_3)\n",
    "        \n",
    "        #Fragment weighted (applying two-third chance of fragmentation)\n",
    "        isFrag = random.choice([1,1,0])\n",
    "        new_nest_seq_tsd_frag = new_nest_seq_tsd\n",
    "        \n",
    "        if isFrag:\n",
    "            new_nest_seq_tsd_frag, frag, cut = fragment(new_nest_seq_tsd)\n",
    "        else:\n",
    "            frag = 100\n",
    "            \n",
    "        nest_len = len(new_nest_seq_tsd_frag)\n",
    "        #nest_name = repeats[k].name\n",
    "    \n",
    "        #Calculate the coordinates of the host TEs and nested TEs after insertion\n",
    "        new_end_1 = start + ins_pos\n",
    "        new_start_2 = new_end_1 + nest_len \n",
    "        new_end_2 = new_start_2 + (length - ins_pos)\n",
    "    \n",
    "        #Apply strand sense\n",
    "        strands = [\"+\", \"-\"]\n",
    "        strand = random.choice(strands)\n",
    "        new_nest_seq_str = new_nest_seq_tsd_frag\n",
    "        \n",
    "        if strand == \"-\":\n",
    "            new_nest_seq_str = str(Seq.Seq(new_nest_seq_tsd_frag).reverse_complement())\n",
    "    \n",
    "        #Prepare updated content to be put into gff list    \n",
    "        nested_te_id = str(n).zfill(6) #prints at least 6 characters wide; i.e. at most 999,999 nested TE insertions\n",
    "        nested_te_id = \"TEn\" + nested_te_id\n",
    "        frag_note = \"\"\n",
    "        frag_note = \";Integrity=\" + str((frag/100))\n",
    "        \n",
    "        ori_seq_te_id = re.sub(\".*_TE\", \"TE\", gff_sel[8])\n",
    "        ori_seq_te_id = re.sub(\";Name.*\", \"\", ori_seq_te_id)\n",
    "        \n",
    "        ori_name_1 = [gff_sel[8].replace(\";Name\",\"_1;Name\").replace(\";Clas\",\"_1;Clas\") + \";Cut_at=\" + str((pct_pos/100)) + \";Cut_by=\" + nest_name + \"_\" + nested_te_id]\n",
    "        ori_line_1 = gff_sel[:3] + [start] + [new_end_1] + gff_sel[5:8] + ori_name_1\n",
    "        \n",
    "        nest_name_in = [\"ID=\" + nest_name + \"_\" + nested_te_id + \";Name=\" + nested_te_id + \";Classification=\" + nest_superfam + \";Identity=\" + str((nest_identity/100)) + frag_note + \";Nest_in=\" + ori_seq_te_id]\n",
    "        \n",
    "        # Nested insertion that has undergone fragmentation does not have 5' tsd\n",
    "        if frag == 100:\n",
    "            nested_line = gff_sel[:2] + [nest_subclas] + [new_end_1+1+tsd_5_len] + [new_start_2-tsd_3_len] + [\".\\t\" + strand + \"\\t.\"] + nest_name_in\n",
    "        else:\n",
    "            nested_line = gff_sel[:2] + [nest_subclas] + [new_end_1+1] + [new_start_2-tsd_3_len] + [\".\\t\" + strand + \"\\t.\"] + nest_name_in\n",
    "     \n",
    "        ori_name_2 = [gff_sel[8].replace(\";Name\",\"_2;Name\").replace(\";Clas\",\"_2;Clas\") + \";Cut_at=\" + str((pct_pos/100)) + \";Cut_by=\" + nest_name + \"_\" + nested_te_id]\n",
    "        ori_line_2 = gff_sel[:3] + [new_start_2] + [new_end_2 -1] + gff_sel[5:8] + ori_name_2\n",
    "    \n",
    "        n += 1\n",
    "    \n",
    "        #Update the entire gff list\n",
    "        index = j[0] + counter\n",
    "        new_gff.pop(index)\n",
    "        new_gff_aux = new_gff[:index]\n",
    "        new_gff_aux.append(ori_line_1)\n",
    "        new_gff_aux.append(nested_line)\n",
    "        new_gff_aux.append(ori_line_2)\n",
    "        new_gff_aux += new_gff[index:]\n",
    "        new_gff = new_gff_aux\n",
    "        new_gff = modify_coords(nest_len, index+3, new_gff)\n",
    "        counter += 2\n",
    "        \n",
    "        #Update the all inserted repeat seq dictionary\n",
    "        chr_id = gff_sel[0]\n",
    "    \n",
    "        ori_seq_name_old = isrt_te_dict[ori_seq_te_id].description\n",
    "        ori_seq_name_old_head = re.sub(\"-.*\", \"-\", ori_seq_name_old)\n",
    "        ori_seq_name_old_tail = re.sub(\".*;I\", \";I\", ori_seq_name_old)\n",
    "        ori_seq_name_old_tail = re.sub(\"]\", \"\", ori_seq_name_old_tail)\n",
    "        nest_note = \";Cut_at=\" + str((pct_pos/100)) + \";Cut_by=\" + nest_name + \"_\" + nested_te_id + \"]\"\n",
    "        ori_seq_name_new = ori_seq_name_old_head + str(new_end_2 -1) + ori_seq_name_old_tail + nest_note\n",
    "\n",
    "        nested_seq_name = nest_name + \"_\" + nested_te_id + \"#\" + nest_superfam + \" [Location=\" + chr_id + \":\" + str(new_end_1+1+tsd_5_len) + \"-\" + str(new_start_2-tsd_3_len) + \";Identity=\" + str(nest_identity/100) + frag_note + \";Nest_in=\" + ori_seq_te_id + \"]\"\n",
    "        \n",
    "        isrt_te_dict[ori_seq_te_id].description = ori_seq_name_new\n",
    "        \n",
    "        #Create and update dictionary for nested TE seq\n",
    "        nest_te_dict[nested_te_id] = {'id': nested_seq_name, 'seq': new_nest_seq_str[tsd_5_len:(nest_len-tsd_3_len)]}\n",
    "                \n",
    "        #Update the genome sequence                \n",
    "        seq = str(genome[chr_id].seq)\n",
    "        new_seq = seq[:new_end_1] + new_nest_seq_str + seq[new_end_1:] \n",
    "        genome[chr_id].seq = new_seq\n",
    "    \n",
    "    return genome, isrt_te_dict, nest_te_dict, new_gff\n",
    "    \n",
    "    \n",
    "#Print final sequence to stdout\n",
    "def print_data(prefix, seq, new_gff):\n",
    "    fasta_out = open(prefix + \"_out_sequence_nest.fasta\", \"w\")\n",
    "    fasta_out.write( \">sequence_nest\\n\" )\n",
    "    for n in range(0,len(seq),100):\n",
    "        fasta_out.write(str(seq[n:n+100]) + \"\\n\")\n",
    "    fasta_out.close()\n",
    "    gff_out = open(prefix + \"_out_repeats_nest.gff\", \"w\")\n",
    "    for i in new_gff:\n",
    "        gff_out.write(\"\\t\".join(map(str,i)) + \"\\n\")\n",
    "    gff_out.close()\n",
    "\n",
    "#Print final sequence to files (function created by THC)\n",
    "def print_genome_nest_data(genome, isrt_te_dict, nest_te_dict, new_gff, params):\n",
    "    #Setup output directory   \n",
    "    file_prefix = str(params['prefix'])\n",
    "    Path(\"./result/sim_\" + file_prefix +\"_genome\").mkdir(parents=True, exist_ok=True)\n",
    "    os.chdir(\"./result/sim_\" + file_prefix +\"_genome\")\n",
    "    \n",
    "    #Output file prefix # temp modification with \"v2\"\n",
    "    file_prefix = str(params['prefix'])\n",
    "    genome_fa = file_prefix + \"_genome_sequence_out_nest_v2.fasta\"\n",
    "    te_fa = file_prefix + \"_repeat_sequence_out_nest_v2.fasta\"\n",
    "    te_gff = file_prefix + \"_repeat_annotation_out_nest_v2.gff\"\n",
    "    \n",
    "    #For genome fasta file\n",
    "    fasta_out = open(genome_fa, \"w\")\n",
    "    for chromosome in genome:\n",
    "        seq = str(genome[chromosome].seq)\n",
    "        fasta_out.write(\">\" + chromosome + \"\\n\" + seq + \"\\n\")\n",
    "    fasta_out.close()\n",
    "    \n",
    "    #For all inserted TE sequences (including nested TEs)\n",
    "    te_fa_out = open(te_fa, \"w\")\n",
    "    for te in isrt_te_dict:\n",
    "        header = str(isrt_te_dict[te].description)\n",
    "        seq = str(isrt_te_dict[te].seq)\n",
    "        te_fa_out.write(\">\" + header + \"\\n\" + seq + \"\\n\")\n",
    "    for nested_te in nest_te_dict:\n",
    "        header = nest_te_dict[nested_te]['id']\n",
    "        seq = nest_te_dict[nested_te]['seq']\n",
    "        te_fa_out.write(\">\" + str(header) + \"\\n\" + str(seq) + \"\\n\")\n",
    "    te_fa_out.close()\n",
    "    \n",
    "    #For the new gff file\n",
    "    gff_out = open(te_gff, \"w\")\n",
    "    for i in new_gff:\n",
    "        gff_out.write(\"\\t\".join(map(str,i)) + \"\\n\")\n",
    "    gff_out.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "023492d3-1b9a-4a1d-9755-531d429a1655",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/powerplant/workspace/cflthc/script/KRIP_TE/10_TEgenomeSimulator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e2148ea-fddf-456a-aa5f-c0dca65aaf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "##For custom genome with multiple chromosoms\n",
    "##Load parameters\n",
    "params_chr = parse_custom_genome_yaml('config_custom_genome_DH_5_10.yml')\n",
    "\n",
    "seed = params_chr['seed']\n",
    "if seed:\n",
    "    random.seed(seed)\n",
    "    \n",
    "#Specify files created from previous step that generats non-overlapping insertions\n",
    "file_prefix = str(params_chr['prefix'])\n",
    "gff_file = \"./result/sim_\" + file_prefix +\"_genome/\" + file_prefix + \"_repeat_annotation_out.gff\"\n",
    "fasta_file = \"./result/sim_\" + file_prefix +\"_genome/\" + file_prefix + \"_genome_sequence_out.fasta\"\n",
    "isrt_te_fasta = \"./result/sim_\" + file_prefix +\"_genome/\" + file_prefix + \"_repeat_sequence_out.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79ef4d34-9a2f-4bb4-89f1-5b2abae17077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load fasta files into dictionaries\n",
    "genome = SeqIO.to_dict(SeqIO.parse(fasta_file,\"fasta\"))\n",
    "isrt_te = load_isrt_te_fa(isrt_te_fasta)\n",
    "\n",
    "#Load non-redundant TE library and the gff file containing all TE insertions\n",
    "repeats_dict = load_repeats_chr(params_chr)\n",
    "gff = load_gff(gff_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa78c0d8-99fb-4824-bc54-165a8ff6ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats = repeats_dict\n",
    "isrt_te_dict = isrt_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be67dec9-982f-4a36-85da-099549ddef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_genome_nests(repeats, isrt_te_dict, gff, genome):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c723de9b-f037-4c06-8418-0ac88b28a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_count = []\n",
    "new_seq = \"\"\n",
    "nest_te_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d33417b1-2d72-430d-b26c-cf164f1b2b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list containing the TE family and the required copies for nested insertion\n",
    "for i in repeats:\n",
    "    rep_count += [i]*int(repeats[i].num_rep*(repeats[i].nest/100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c1d15ef-7764-49c2-b6d3-c2a2e8765479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acquire the index of TEs from gff file (excluding Alu and SINE)\n",
    "vec_cand = filter_nonest(gff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a34c50b3-87db-466b-a046-33c5d63a2613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly pick the index of TE loci to be inserted with nested TEs\n",
    "insert_index = random.sample(vec_cand, len(rep_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbbcc81c-826e-4eb2-b790-38d55b3be5dd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ATCOPI1#LTR/Copia',\n",
       " 'ATCOPIA10#LTR/Copia',\n",
       " 'ATCOPIA10#LTR/Copia',\n",
       " 'ATCOPIA12#LTR/Copia',\n",
       " 'ATCOPIA13#LTR/Copia',\n",
       " 'ATCOPIA13#LTR/Copia',\n",
       " 'ATCOPIA15#LTR/Copia',\n",
       " 'ATCOPIA16#LTR/Copia',\n",
       " 'ATCOPIA17#LTR/Copia',\n",
       " 'ATCOPIA18A#LTR/Copia',\n",
       " 'ATCOPIA18#LTR/Copia',\n",
       " 'ATCOPIA20#LTR/Copia',\n",
       " 'ATCOPIA21#LTR/Copia',\n",
       " 'ATCOPIA22#LTR/Copia',\n",
       " 'ATCOPIA26#LTR/Copia',\n",
       " 'ATCOPIA26#LTR/Copia',\n",
       " 'ATCOPIA27#LTR/Copia',\n",
       " 'ATCOPIA27#LTR/Copia',\n",
       " 'ATCOPIA28#LTR/Copia',\n",
       " 'ATCOPIA29#LTR/Copia',\n",
       " 'ATCOPIA29#LTR/Copia',\n",
       " 'ATCOPIA32#LTR/Copia',\n",
       " 'ATCOPIA33#LTR/Copia',\n",
       " 'ATCOPIA33#LTR/Copia',\n",
       " 'ATCOPIA35#LTR/Copia',\n",
       " 'ATCOPIA35#LTR/Copia',\n",
       " 'ATCOPIA36#LTR/Copia',\n",
       " 'ATCOPIA36#LTR/Copia',\n",
       " 'ATCOPIA37#LTR/Copia',\n",
       " 'ATCOPIA38B#LTR/Copia',\n",
       " 'ATCOPIA39#LTR/Copia',\n",
       " 'ATCOPIA3#LTR/Copia',\n",
       " 'ATCOPIA3#LTR/Copia',\n",
       " 'ATCOPIA43#LTR/Copia',\n",
       " 'ATCOPIA44#LTR/Copia',\n",
       " 'ATCOPIA45#LTR/Copia',\n",
       " 'ATCOPIA45#LTR/Copia',\n",
       " 'ATCOPIA46#LTR/Copia',\n",
       " 'ATCOPIA47#LTR/Copia',\n",
       " 'ATCOPIA47#LTR/Copia',\n",
       " 'ATCOPIA48#LTR/Copia',\n",
       " 'ATCOPIA49#LTR/Copia',\n",
       " 'ATCOPIA50#LTR/Copia',\n",
       " 'ATCOPIA50#LTR/Copia',\n",
       " 'ATCOPIA51#LTR/Copia',\n",
       " 'ATCOPIA51#LTR/Copia',\n",
       " 'ATCOPIA52#LTR/Copia',\n",
       " 'ATCOPIA53#LTR/Copia',\n",
       " 'ATCOPIA55#LTR/Copia',\n",
       " 'ATCOPIA57#LTR/Copia',\n",
       " 'ATCOPIA60#LTR/Copia',\n",
       " 'ATCOPIA61#LTR/Copia',\n",
       " 'ATCOPIA63#LTR/Copia',\n",
       " 'ATCOPIA63#LTR/Copia',\n",
       " 'ATCOPIA67#LTR/Copia',\n",
       " 'ATCOPIA69#LTR/Copia',\n",
       " 'ATCOPIA70#LTR/Copia',\n",
       " 'ATCOPIA70#LTR/Copia',\n",
       " 'ATCOPIA71#LTR/Copia',\n",
       " 'ATCOPIA72#LTR/Copia',\n",
       " 'ATCOPIA72#LTR/Copia',\n",
       " 'ATCOPIA75#LTR/Copia',\n",
       " 'ATCOPIA76#LTR/Copia',\n",
       " 'ATCOPIA78#LTR/Copia',\n",
       " 'ATCOPIA79#LTR/Copia',\n",
       " 'ATCOPIA7#LTR/Copia',\n",
       " 'ATCOPIA82#LTR/Copia',\n",
       " 'ATCOPIA83#LTR/Copia',\n",
       " 'ATCOPIA86#LTR/Copia',\n",
       " 'ATCOPIA86#LTR/Copia',\n",
       " 'ATCOPIA87#LTR/Copia',\n",
       " 'ATCOPIA87#LTR/Copia',\n",
       " 'ATCOPIA88#LTR/Copia',\n",
       " 'ATCOPIA89#LTR/Copia',\n",
       " 'ATCOPIA89#LTR/Copia',\n",
       " 'ATCOPIA91#LTR/Copia',\n",
       " 'ATCOPIA92#LTR/Copia',\n",
       " 'ATCOPIA93#LTR/Copia',\n",
       " 'ATCOPIA93#LTR/Copia',\n",
       " 'ATCOPIA94#LTR/Copia',\n",
       " 'ATCOPIA94#LTR/Copia',\n",
       " 'ATCOPIA31A_LTR#LTR/Copia',\n",
       " 'ATCOPIA32B_LTR#LTR/Copia',\n",
       " 'ATCOPIA40_I#LTR/Copia',\n",
       " 'ENDOVIR1_I#LTR/Copia',\n",
       " 'Os0078_INT#LTR/Copia',\n",
       " 'Os0078_INT#LTR/Copia',\n",
       " 'Os0082_LTR#LTR/Copia',\n",
       " 'Os0083_LTR#LTR/Copia',\n",
       " 'Os0083_LTR#LTR/Copia',\n",
       " 'Os0083_LTR#LTR/Copia',\n",
       " 'Os0323_INT#LTR/Copia',\n",
       " 'Os0323_INT#LTR/Copia',\n",
       " 'Os0338_INT#LTR/Copia',\n",
       " 'Os0352_LTR#LTR/Copia',\n",
       " 'Os0352_LTR#LTR/Copia',\n",
       " 'Os1077_LTR#LTR/Copia',\n",
       " 'Os1077_LTR#LTR/Copia',\n",
       " 'Os2617_LTR#LTR/Copia',\n",
       " 'Os2739_LTR#LTR/Copia',\n",
       " 'Os2852_LTR#LTR/Copia',\n",
       " 'Os2852_LTR#LTR/Copia',\n",
       " 'Os3411_LTR#LTR/Copia',\n",
       " 'Os3425_LTR#LTR/Copia',\n",
       " 'Os3468_LTR#LTR/Copia',\n",
       " 'Os3468_LTR#LTR/Copia',\n",
       " 'Os3553_LTR#LTR/Copia',\n",
       " 'Os3553_LTR#LTR/Copia',\n",
       " 'Os3597_LTR#LTR/Copia',\n",
       " 'Os3638_LTR#LTR/Copia',\n",
       " 'ATGP10#LTR/Ty3',\n",
       " 'ATGP11#LTR/Ty3',\n",
       " 'ATGP11#LTR/Ty3',\n",
       " 'ATGP1#LTR/Ty3',\n",
       " 'ATGP3B#LTR/Ty3',\n",
       " 'ATGP5A#LTR/Ty3',\n",
       " 'ATGP6#LTR/Ty3',\n",
       " 'ATGP8#LTR/Ty3',\n",
       " 'ATGP8#LTR/Ty3',\n",
       " 'ATHILA2#LTR/Ty3',\n",
       " 'ATHILA4C#LTR/Ty3',\n",
       " 'ATHILA5#LTR/Ty3',\n",
       " 'ATHILA6A#LTR/Ty3',\n",
       " 'ATHILA7#LTR/Ty3',\n",
       " 'ATLANTYS1#LTR/Ty3',\n",
       " 'ATLANTYS2#LTR/Ty3',\n",
       " 'ATLANTYS2#LTR/Ty3',\n",
       " 'ATHILA4B_LTR#LTR/Ty3',\n",
       " 'ATHILA4D_LTR#LTR/Ty3',\n",
       " 'ATHILA4_I#LTR/Ty3',\n",
       " 'ATHILA6B_I#LTR/Ty3',\n",
       " 'ATHILA6B_I#LTR/Ty3',\n",
       " 'ATHILA6C_I#LTR/Ty3',\n",
       " 'ATHILA7A_I#LTR/Ty3',\n",
       " 'ROMANIAT5#LTR/Ty3',\n",
       " 'TA1_AT#LTR/Ty3',\n",
       " 'TA1_AT#LTR/Ty3',\n",
       " 'TAT1_ATH#LTR/Ty3',\n",
       " 'Os0118_LTR#LTR/Gypsy',\n",
       " 'Os0133_INT#LTR/Gypsy',\n",
       " 'Os0133_INT#LTR/Gypsy',\n",
       " 'Os0141_LTR#LTR/Gypsy',\n",
       " 'Os0142_LTR#LTR/Gypsy',\n",
       " 'Os0142_LTR#LTR/Gypsy',\n",
       " 'Os0172_INT_IC_Dasheng#LTR/Gypsy',\n",
       " 'Os0209_LTR#LTR/Gypsy',\n",
       " 'Os0209_LTR#LTR/Gypsy',\n",
       " 'Os0262_INT#LTR/Gypsy',\n",
       " 'Os0262_INT#LTR/Gypsy',\n",
       " 'Os0264_LTR#LTR/Gypsy',\n",
       " 'Os0271_INT#LTR/Gypsy',\n",
       " 'Os0271_INT#LTR/Gypsy',\n",
       " 'Os0320_LTR#LTR/Gypsy',\n",
       " 'Os0329_LTR#LTR/Gypsy',\n",
       " 'Os0346_LTR#LTR/Gypsy',\n",
       " 'Os0404_LTR#LTR/Gypsy',\n",
       " 'Os0498_LTR#LTR/Gypsy',\n",
       " 'Os0706_LTR#LTR/Gypsy',\n",
       " 'Os0726_LTR#LTR/Gypsy',\n",
       " 'Os0726_LTR#LTR/Gypsy',\n",
       " 'Os0777_LTR#LTR/Gypsy',\n",
       " 'Os0869_LTR#LTR/Gypsy',\n",
       " 'Os0869_LTR#LTR/Gypsy',\n",
       " 'Os1076_LTR#LTR/Gypsy',\n",
       " 'Os1082_LTR#LTR/Gypsy',\n",
       " 'Os1330_LTR_ICL#LTR/Gypsy',\n",
       " 'Os1598_LTR#LTR/Gypsy',\n",
       " 'Os1699_LTR#LTR/Gypsy',\n",
       " 'Os1718_LTR#LTR/Gypsy',\n",
       " 'Os1737_LTR#LTR/Gypsy',\n",
       " 'Os1742_LTR#LTR/Gypsy',\n",
       " 'Os1888_LTR#LTR/Gypsy',\n",
       " 'Os1980_LTR#LTR/Gypsy',\n",
       " 'Os2013_LTR#LTR/Gypsy',\n",
       " 'Os2013_LTR#LTR/Gypsy',\n",
       " 'Os2245_INT_Dasheng#LTR/Gypsy',\n",
       " 'Os2258_LTR#LTR/Gypsy',\n",
       " 'Os2278_LTR#LTR/Gypsy',\n",
       " 'Os2344_LTR#LTR/Gypsy',\n",
       " 'Os2344_LTR#LTR/Gypsy',\n",
       " 'Os2490_LTR#LTR/Gypsy',\n",
       " 'Os2621_LTR#LTR/Gypsy',\n",
       " 'Os2710_LTR#LTR/Gypsy',\n",
       " 'Os2724_LTR#LTR/Gypsy',\n",
       " 'Os2796_LTR#LTR/Gypsy',\n",
       " 'Os3087_INT#LTR/Gypsy',\n",
       " 'Os3096_LTR#LTR/Gypsy',\n",
       " 'Os3341_LTR#LTR/Gypsy',\n",
       " 'Os3496_LTR#LTR/Gypsy',\n",
       " 'Os3508_LTR#LTR/Gypsy']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b336b53-702c-499e-a597-24a0950215be",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2264,\n",
       " 9602,\n",
       " 1066,\n",
       " 4294,\n",
       " 1988,\n",
       " 8349,\n",
       " 7576,\n",
       " 7956,\n",
       " 11003,\n",
       " 6395,\n",
       " 3540,\n",
       " 1587,\n",
       " 8223,\n",
       " 477,\n",
       " 6563,\n",
       " 7294,\n",
       " 10259,\n",
       " 34,\n",
       " 11750,\n",
       " 7506,\n",
       " 4482,\n",
       " 3852,\n",
       " 9980,\n",
       " 1728,\n",
       " 5338,\n",
       " 514,\n",
       " 376,\n",
       " 428,\n",
       " 10967,\n",
       " 9133,\n",
       " 153,\n",
       " 6421,\n",
       " 11589,\n",
       " 3650,\n",
       " 7114,\n",
       " 488,\n",
       " 8901,\n",
       " 3734,\n",
       " 7380,\n",
       " 8355,\n",
       " 9326,\n",
       " 3925,\n",
       " 5822,\n",
       " 3889,\n",
       " 11429,\n",
       " 3686,\n",
       " 7746,\n",
       " 4876,\n",
       " 362,\n",
       " 7011,\n",
       " 9385,\n",
       " 10846,\n",
       " 1691,\n",
       " 3141,\n",
       " 10632,\n",
       " 4987,\n",
       " 2037,\n",
       " 5600,\n",
       " 8440,\n",
       " 8558,\n",
       " 11318,\n",
       " 3207,\n",
       " 5104,\n",
       " 4783,\n",
       " 9919,\n",
       " 8415,\n",
       " 8518,\n",
       " 6623,\n",
       " 9943,\n",
       " 582,\n",
       " 8093,\n",
       " 4087,\n",
       " 6805,\n",
       " 6981,\n",
       " 11225,\n",
       " 2924,\n",
       " 6185,\n",
       " 9257,\n",
       " 11873,\n",
       " 11388,\n",
       " 6314,\n",
       " 1461,\n",
       " 7398,\n",
       " 11209,\n",
       " 8570,\n",
       " 1822,\n",
       " 2766,\n",
       " 8788,\n",
       " 6621,\n",
       " 6244,\n",
       " 8253,\n",
       " 497,\n",
       " 7908,\n",
       " 734,\n",
       " 5189,\n",
       " 11879,\n",
       " 10383,\n",
       " 10015,\n",
       " 9757,\n",
       " 6627,\n",
       " 10927,\n",
       " 2881,\n",
       " 2852,\n",
       " 8465,\n",
       " 3822,\n",
       " 205,\n",
       " 3368,\n",
       " 9102,\n",
       " 9249,\n",
       " 3910,\n",
       " 6808,\n",
       " 8662,\n",
       " 5791,\n",
       " 9751,\n",
       " 5953,\n",
       " 7738,\n",
       " 4533,\n",
       " 11132,\n",
       " 9244,\n",
       " 10283,\n",
       " 95,\n",
       " 6462,\n",
       " 8641,\n",
       " 2176,\n",
       " 8748,\n",
       " 9470,\n",
       " 3466,\n",
       " 7181,\n",
       " 949,\n",
       " 8108,\n",
       " 6145,\n",
       " 9615,\n",
       " 9351,\n",
       " 3374,\n",
       " 8509,\n",
       " 6965,\n",
       " 8172,\n",
       " 6012,\n",
       " 6982,\n",
       " 5829,\n",
       " 25,\n",
       " 9083,\n",
       " 9112,\n",
       " 10534,\n",
       " 10343,\n",
       " 5574,\n",
       " 7722,\n",
       " 10130,\n",
       " 471,\n",
       " 3866,\n",
       " 10730,\n",
       " 2993,\n",
       " 9290,\n",
       " 9865,\n",
       " 3053,\n",
       " 1548,\n",
       " 9295,\n",
       " 4297,\n",
       " 546,\n",
       " 11366,\n",
       " 1192,\n",
       " 1404,\n",
       " 280,\n",
       " 7634,\n",
       " 243,\n",
       " 4734,\n",
       " 4202,\n",
       " 4523,\n",
       " 1848,\n",
       " 10555,\n",
       " 3119,\n",
       " 5802,\n",
       " 4885,\n",
       " 1175,\n",
       " 2832,\n",
       " 2695,\n",
       " 4296,\n",
       " 8897,\n",
       " 2843,\n",
       " 11089,\n",
       " 4596,\n",
       " 10945,\n",
       " 4955,\n",
       " 7662,\n",
       " 11865,\n",
       " 5415,\n",
       " 8367,\n",
       " 7982,\n",
       " 1926,\n",
       " 398]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db473a7b-cf42-41c0-a2c7-02929dfb139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gff = gff\n",
    "sorted_table = sorted(zip(insert_index, rep_count))\n",
    "counter = 0\n",
    "n = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f16a745-9b15-4d8c-b929-7747d22e6792",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 'Os0133_INT#LTR/Gypsy')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_table[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1b5b82a-c0b1-4f87-8ea3-f4f4d07b3b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 'Os0133_INT#LTR/Gypsy'), 'ATCOPI1#LTR/Copia')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = list(zip(sorted_table, rep_count))\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aed449fd-7b11-4a2b-85a5-7344f1bcd765",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = [25, 'Os0133_INT#LTR/Gypsy']\n",
    "k = 'ATCOPI1#LTR/Copia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc6f0ced-f8a4-4b9f-8dcc-7a35df366fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gff_sel = new_gff[j[0] + counter]\n",
    "start = int(gff_sel[3])\n",
    "end = int(gff_sel[4])\n",
    "length = end - start +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80a2eeec-5cf1-4c14-a30e-470842dc2e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chr1',\n",
       " 'TEgenomeSimulator',\n",
       " 'DNA/CACTA',\n",
       " '612179',\n",
       " '618271',\n",
       " '.',\n",
       " '-',\n",
       " '.',\n",
       " 'ID=ATENSPM6#DNA/CACTA_TE0000026;Name=TE0000026;Classification=TIR_transposon;Identity=0.79;Integrity=0.69']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gff_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aedc138e-abfd-4a76-b584-65f4871d6719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decide on the position of nested insertion in association to the length of host TE locus \n",
    "pct_pos = random.randint(40,60)\n",
    "ins_pos = int(round((pct_pos/100.0) * length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51f8bbf9-7f11-430f-bb37-f84b615314c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get family name, subclass and superfamily of nested TE\n",
    "nest_name = repeats[k].name\n",
    "nest_subclas = repeats[k].subclass\n",
    "nest_superfam = repeats[k].superfamily \n",
    "\n",
    "#Create SNPs, indels and TSD for the nested TE\n",
    "nest_seq = repeats[k].sequence\n",
    "nest_identity = get_identity(repeats[k].identity, repeats[k].sd)\n",
    "nest_identity_fix = nest_identity + (100 - nest_identity) * 0.5\n",
    "nest_indels = repeats[k].indels\n",
    "base_changes_vec, indels_changes_vec = generate_mismatches(nest_seq, nest_identity_fix, nest_indels)\n",
    "nest_seq_mismatches = add_base_changes(nest_seq, base_changes_vec)\n",
    "new_nest_seq = add_indels(nest_seq_mismatches, indels_changes_vec)\n",
    "\n",
    "new_nest_seq_tsd = new_nest_seq\n",
    "tsd_5_len = tsd_3_len = 0\n",
    "if repeats[k].tsd != [0, 0]:\n",
    "    TSD_min = repeats[k].tsd[0]\n",
    "    TSD_max = repeats[k].tsd[1]\n",
    "    tsd_seq_5, tsd_seq_3 = create_TSD(TSD_min, TSD_max, nest_identity_fix, nest_indels)\n",
    "    new_nest_seq_tsd = tsd_seq_5 + new_nest_seq + tsd_seq_3\n",
    "    tsd_5_len = len(tsd_seq_5)\n",
    "    tsd_3_len = len(tsd_seq_3)\n",
    "    \n",
    "#Fragment weighted (applying two-third chance of fragmentation)\n",
    "isFrag = random.choice([1,1,0])\n",
    "new_nest_seq_tsd_frag = new_nest_seq_tsd\n",
    "\n",
    "if isFrag:\n",
    "    new_nest_seq_tsd_frag, frag, cut = fragment(new_nest_seq_tsd)\n",
    "else:\n",
    "    frag = 100\n",
    "    \n",
    "nest_len = len(new_nest_seq_tsd_frag)\n",
    "#nest_name = repeats[k].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f51e4b2-f73e-4c1b-8692-51a31d9368a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TATGT'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsd_seq_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ac05ed1-4143-4a1e-9038-5e254d7d6b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TATGT'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsd_seq_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c8313a6-77cc-446a-84ef-e5c3e5093418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isFrag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0f6231e-a9c5-4932-a690-c72f1363a3fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4101"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_nest_seq_tsd_frag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9ab835e-877e-4291-8f91-7f51a502fe91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0a3a613-3abc-4704-9b81-15a2b6e4954a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1025"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10eb92d7-da85-42a0-9961-47185dba1605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4101"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nest_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f79af399-6e4f-426c-acba-6408af4c6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the coordinates of the host TEs and nested TEs after insertion\n",
    "new_end_1 = start + ins_pos\n",
    "new_start_2 = new_end_1 + nest_len \n",
    "new_end_2 = new_start_2 + (length - ins_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec520eb3-a9fe-4a95-8cbf-e9d0ab72a8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "612179"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddb85390-c62c-4aad-b1c4-3ee9deb4f47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615165"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_end_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d39675e8-6d43-4ff9-92f9-a26c5f86af65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2986"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "620f3672-1484-428c-8e03-d5ffc93caca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "619266"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_start_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b861541b-cb84-4983-bd87-e663f7238861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622373"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_end_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8529e7a7-bd06-46d1-9666-cbd1faddc37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply strand sense\n",
    "strands = [\"+\", \"-\"]\n",
    "strand = random.choice(strands)\n",
    "new_nest_seq_str = new_nest_seq_tsd_frag\n",
    "\n",
    "if strand == \"-\":\n",
    "    new_nest_seq_str = str(Seq.Seq(new_nest_seq_tsd_frag).reverse_complement())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11a6bebb-926a-4019-abbe-57f559dd1c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare updated content to be put into gff list    \n",
    "nested_te_id = str(n).zfill(6) #prints at least 6 characters wide; i.e. at most 999,999 nested TE insertions\n",
    "nested_te_id = \"TEn\" + nested_te_id\n",
    "frag_note = \"\"\n",
    "frag_note = \";Integrity=\" + str((frag/100))\n",
    "\n",
    "ori_seq_te_id = re.sub(\".*_TE\", \"TE\", gff_sel[8])\n",
    "ori_seq_te_id = re.sub(\";Name.*\", \"\", ori_seq_te_id)\n",
    "\n",
    "ori_name_1 = [gff_sel[8].replace(\";Name\",\"_1;Name\").replace(\";Clas\",\"_1;Clas\") + \";Cut_at=\" + str((pct_pos/100)) + \";Cut_by=\" + nest_name + \"_\" + nested_te_id]\n",
    "ori_line_1 = gff_sel[:3] + [start] + [new_end_1] + gff_sel[5:8] + ori_name_1\n",
    "\n",
    "nest_name_in = [\"ID=\" + nest_name + \"_\" + nested_te_id + \";Name=\" + nested_te_id + \";Classification=\" + nest_superfam + \";Identity=\" + str((nest_identity/100)) + frag_note + \";Nest_in=\" + ori_seq_te_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2e2fb4c-1412-47b9-9e94-201980df8dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chr1',\n",
       " 'TEgenomeSimulator',\n",
       " 'DNA/CACTA',\n",
       " 612179,\n",
       " 615165,\n",
       " '.',\n",
       " '-',\n",
       " '.',\n",
       " 'ID=ATENSPM6#DNA/CACTA_TE0000026_1;Name=TE0000026_1;Classification=TIR_transposon;Identity=0.79;Integrity=0.69;Cut_at=0.49;Cut_by=ATCOPI1#LTR/Copia_TEn000001']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_line_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3361b504-6817-45cd-b12c-fa2036280adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested insertion that has undergone fragmentation does not have 5' tsd\n",
    "if frag == 100:\n",
    "    nested_line = gff_sel[:2] + [nest_subclas] + [new_end_1+1+tsd_5_len] + [new_start_2-tsd_3_len] + [\".\\t\" + strand + \"\\t.\"] + nest_name_in\n",
    "else:\n",
    "    nested_line = gff_sel[:2] + [nest_subclas] + [new_end_1+1] + [new_start_2-tsd_3_len] + [\".\\t\" + strand + \"\\t.\"] + nest_name_in\n",
    "    \n",
    "    ori_name_2 = [gff_sel[8].replace(\";Name\",\"_2;Name\").replace(\";Clas\",\"_2;Clas\") + \";Cut_at=\" + str((pct_pos/100)) + \";Cut_by=\" + nest_name + \"_\" + nested_te_id]\n",
    "    ori_line_2 = gff_sel[:3] + [new_start_2] + [new_end_2 -1] + gff_sel[5:8] + ori_name_2\n",
    "\n",
    "n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4dde89f-80ce-4833-9648-c251e66ada85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chr1',\n",
       " 'TEgenomeSimulator',\n",
       " 'LTR/Copia',\n",
       " 615166,\n",
       " 619261,\n",
       " '.\\t+\\t.',\n",
       " 'ID=ATCOPI1#LTR/Copia_TEn000001;Name=TEn000001;Classification=LTR_retrotransposon;Identity=0.88;Integrity=0.8;Nest_in=TE0000026']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1821f305-90ae-4b19-be07-eb328be3bfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chr1',\n",
       " 'TEgenomeSimulator',\n",
       " 'DNA/CACTA',\n",
       " 619266,\n",
       " 622372,\n",
       " '.',\n",
       " '-',\n",
       " '.',\n",
       " 'ID=ATENSPM6#DNA/CACTA_TE0000026_2;Name=TE0000026_2;Classification=TIR_transposon;Identity=0.79;Integrity=0.69;Cut_at=0.49;Cut_by=ATCOPI1#LTR/Copia_TEn000001']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_line_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc4de864-1dde-4ac1-a749-42e0f11eebdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ec57374-44f7-4dbf-801e-bf7a3d73bfa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "432ed2ba-7448-4819-9a69-e0f38afc5ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the entire gff list\n",
    "index = j[0] + counter\n",
    "new_gff.pop(index) # remove original index 25\n",
    "new_gff_aux = new_gff[:index]   # index 0-24\n",
    "new_gff_aux.append(ori_line_1)  # 25\n",
    "new_gff_aux.append(nested_line) # 26\n",
    "new_gff_aux.append(ori_line_2)  # 27\n",
    "new_gff_aux += new_gff[index:]  # paste original index 26+ (became index 25 after pop) \n",
    "new_gff = new_gff_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b68ee381-1909-4f11-872e-738698d5593f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chr1',\n",
       " 'TEgenomeSimulator',\n",
       " 'DNA/CACTA',\n",
       " 612179,\n",
       " 615165,\n",
       " '.',\n",
       " '-',\n",
       " '.',\n",
       " 'ID=ATENSPM6#DNA/CACTA_TE0000026_1;Name=TE0000026_1;Classification=TIR_transposon;Identity=0.79;Integrity=0.69;Cut_at=0.49;Cut_by=ATCOPI1#LTR/Copia_TEn000001']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_gff[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "08ac0911-7bad-4391-b2bb-e0fb623ab0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chr1',\n",
       " 'TEgenomeSimulator',\n",
       " 'LTR/Copia',\n",
       " 615166,\n",
       " 619261,\n",
       " '.\\t+\\t.',\n",
       " 'ID=ATCOPI1#LTR/Copia_TEn000001;Name=TEn000001;Classification=LTR_retrotransposon;Identity=0.88;Integrity=0.8;Nest_in=TE0000026']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_gff[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed769935-82bd-4708-90fc-a966c29adfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chr1',\n",
       " 'TEgenomeSimulator',\n",
       " 'DNA/CACTA',\n",
       " 619266,\n",
       " 622372,\n",
       " '.',\n",
       " '-',\n",
       " '.',\n",
       " 'ID=ATENSPM6#DNA/CACTA_TE0000026_2;Name=TE0000026_2;Classification=TIR_transposon;Identity=0.79;Integrity=0.69;Cut_at=0.49;Cut_by=ATCOPI1#LTR/Copia_TEn000001']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_gff[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c8d3adec-5d82-41b1-bbbd-5a48918053e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chr1',\n",
       " 'TEgenomeSimulator',\n",
       " 'DNAnona/hAT',\n",
       " '636232',\n",
       " '636358',\n",
       " '.',\n",
       " '-',\n",
       " '.',\n",
       " 'ID=Os1366#DNAnona/hAT_TE0000027;Name=TE0000027;Classification=TIR_transposon;Identity=0.8;Integrity=0.78']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_gff[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8b8bfd6-5316-4f55-88c4-8858b5062098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d433581-eff3-4c98-81a3-8a9272fcd1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def modify_coords(offset, index, new_gff):\n",
    "offset = nest_len\n",
    "index = index + 3\n",
    "\n",
    "new_gff_aux = []\n",
    "for i in range(index, len(new_gff)):\n",
    "    start = int(new_gff[i][3]) + offset\n",
    "    new_gff[i][3] = str(start)\n",
    "    end = int(new_gff[i][4]) + offset\n",
    "    new_gff[i][4] = str(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "042fb96e-8466-4c8f-b789-d9180942d0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chr1',\n",
       " 'TEgenomeSimulator',\n",
       " 'DNAnona/hAT',\n",
       " '640333',\n",
       " '640459',\n",
       " '.',\n",
       " '-',\n",
       " '.',\n",
       " 'ID=Os1366#DNAnona/hAT_TE0000027;Name=TE0000027;Classification=TIR_transposon;Identity=0.8;Integrity=0.78']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_gff[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a7bc48e5-1613-4cba-b4a7-0f1f85b54b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_gff = modify_coords(nest_len, index+3, new_gff)\n",
    "counter += 2 # to adjust the selected gff index for nested insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e1b439df-55a2-4687-aa5e-b122444bd30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the all inserted repeat seq dictionary\n",
    "chr_id = gff_sel[0]\n",
    "\n",
    "ori_seq_name_old = isrt_te_dict[ori_seq_te_id].description\n",
    "ori_seq_name_old_head = re.sub(\"-.*\", \"-\", ori_seq_name_old)\n",
    "ori_seq_name_old_tail = re.sub(\".*;I\", \";I\", ori_seq_name_old)\n",
    "ori_seq_name_old_tail = re.sub(\"]\", \"\", ori_seq_name_old_tail)\n",
    "nest_note = \";Cut_at=\" + str((pct_pos/100)) + \";Cut_by=\" + nest_name + \"_\" + nested_te_id + \"]\"\n",
    "ori_seq_name_new = ori_seq_name_old_head + str(new_end_2 -1) + ori_seq_name_old_tail + nest_note\n",
    "\n",
    "nested_seq_name = nest_name + \"_\" + nested_te_id + \"#\" + nest_superfam + \" [Location=\" + chr_id + \":\" + str(new_end_1+1+tsd_5_len) + \"-\" + str(new_start_2-tsd_3_len) + \";Identity=\" + str(nest_identity/100) + frag_note + \";Nest_in=\" + ori_seq_te_id + \"]\"\n",
    "\n",
    "isrt_te_dict[ori_seq_te_id].description = ori_seq_name_new\n",
    "\n",
    "#Create and update dictionary for nested TE seq\n",
    "nest_te_dict[nested_te_id] = {'id': nested_seq_name, 'seq': new_nest_seq_str[tsd_5_len:(nest_len-tsd_3_len)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a8aad7c-61c1-47a3-ade5-d1ef5eeead32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr1'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c2186cfa-6240-4057-a82d-60373d5f32f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the genome sequence                \n",
    "seq = str(genome[chr_id].seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "41d6b959-e78b-4e39-9ae4-498f28ab88cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11106596"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "19faae96-cd0e-4ae4-b9d8-dfeac7a4ac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_seq = seq[:new_end_1] + new_nest_seq_str + seq[new_end_1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "734b5e71-6096-45e3-b0fb-b7df2d94638a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615165"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_end_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a50b2bbc-5431-4b75-b441-f57881ae3848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4101"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_nest_seq_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "941a567c-a7f5-497a-a089-e069a0259e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615165"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq[:new_end_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "97dd5b61-7581-4d1a-94e2-5e034e1c16d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10491431"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq[new_end_1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "60d11e86-43e5-4118-a82b-cff88140fddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11110697"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4979c1f1-26db-4669-81c4-9aa40c337b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome[chr_id].seq = new_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d6c203a0-0fe4-4762-8a39-d901da6da29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11110697"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genome[chr_id].seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9733d2e6-0fdd-443f-985e-4c8f0b554b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c6a08d-70ba-4b8c-a064-9b1cb5b9081d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ede3ce4-2a90-4f09-a2ac-fb2ddb2958fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,k in zip(sorted_table, rep_count):\n",
    "    gff_sel = new_gff[j[0] + counter]\n",
    "    start = int(gff_sel[3])\n",
    "    end = int(gff_sel[4])\n",
    "    length = end - start +1\n",
    "    \n",
    "    #Decide on the position of nested insertion in association to the length of host TE locus \n",
    "    pct_pos = random.randint(40,60)\n",
    "    ins_pos = int(round((pct_pos/100.0) * length))\n",
    "    \n",
    "    #Get family name, subclass and superfamily of nested TE\n",
    "    nest_name = repeats[k].name\n",
    "    nest_subclas = repeats[k].subclass\n",
    "    nest_superfam = repeats[k].superfamily \n",
    "    \n",
    "    #Create SNPs, indels and TSD for the nested TE\n",
    "    nest_seq = repeats[k].sequence\n",
    "    nest_identity = get_identity(repeats[k].identity, repeats[k].sd)\n",
    "    nest_identity_fix = nest_identity + (100 - nest_identity) * 0.5\n",
    "    nest_indels = repeats[k].indels\n",
    "    base_changes_vec, indels_changes_vec = generate_mismatches(nest_seq, nest_identity_fix, nest_indels)\n",
    "    nest_seq_mismatches = add_base_changes(nest_seq, base_changes_vec)\n",
    "    new_nest_seq = add_indels(nest_seq_mismatches, indels_changes_vec)\n",
    "    \n",
    "    new_nest_seq_tsd = new_nest_seq\n",
    "    tsd_5_len = tsd_3_len = 0\n",
    "    if repeats[k].tsd != [0, 0]:\n",
    "        TSD_min = repeats[k].tsd[0]\n",
    "        TSD_max = repeats[k].tsd[1]\n",
    "        tsd_seq_5, tsd_seq_3 = create_TSD(TSD_min, TSD_max, nest_identity_fix, nest_indels)\n",
    "        new_nest_seq_tsd = tsd_seq_5 + new_nest_seq + tsd_seq_3\n",
    "        tsd_5_len = len(tsd_seq_5)\n",
    "        tsd_3_len = len(tsd_seq_3)\n",
    "        \n",
    "    #Fragment weighted (applying two-third chance of fragmentation)\n",
    "    isFrag = random.choice([1,1,0])\n",
    "    new_nest_seq_tsd_frag = new_nest_seq_tsd\n",
    "    \n",
    "    if isFrag:\n",
    "        new_nest_seq_tsd_frag, frag, cut = fragment(new_nest_seq_tsd)\n",
    "    else:\n",
    "        frag = 100\n",
    "        \n",
    "    nest_len = len(new_nest_seq_tsd_frag)\n",
    "    #nest_name = repeats[k].name\n",
    "    \n",
    "    #Calculate the coordinates of the host TEs and nested TEs after insertion\n",
    "    new_end_1 = start + ins_pos\n",
    "    new_start_2 = new_end_1 + nest_len \n",
    "    new_end_2 = new_start_2 + (length - ins_pos)\n",
    "    \n",
    "    #Apply strand sense\n",
    "    strands = [\"+\", \"-\"]\n",
    "    strand = random.choice(strands)\n",
    "    new_nest_seq_str = new_nest_seq_tsd_frag\n",
    "    \n",
    "    if strand == \"-\":\n",
    "        new_nest_seq_str = str(Seq.Seq(new_nest_seq_tsd_frag).reverse_complement())\n",
    "    \n",
    "    #Prepare updated content to be put into gff list    \n",
    "    nested_te_id = str(n).zfill(6) #prints at least 6 characters wide; i.e. at most 999,999 nested TE insertions\n",
    "    nested_te_id = \"TEn\" + nested_te_id\n",
    "    frag_note = \"\"\n",
    "    frag_note = \";Integrity=\" + str((frag/100))\n",
    "    \n",
    "    ori_seq_te_id = re.sub(\".*_TE\", \"TE\", gff_sel[8])\n",
    "    ori_seq_te_id = re.sub(\";Name.*\", \"\", ori_seq_te_id)\n",
    "    \n",
    "    ori_name_1 = [gff_sel[8].replace(\";Name\",\"_1;Name\").replace(\";Clas\",\"_1;Clas\") + \";Cut_at=\" + str((pct_pos/100)) + \";Cut_by=\" + nest_name + \"_\" + nested_te_id]\n",
    "    ori_line_1 = gff_sel[:3] + [start] + [new_end_1] + gff_sel[5:8] + ori_name_1\n",
    "    \n",
    "    nest_name_in = [\"ID=\" + nest_name + \"_\" + nested_te_id + \";Name=\" + nested_te_id + \";Classification=\" + nest_superfam + \";Identity=\" + str((nest_identity/100)) + frag_note + \";Nest_in=\" + ori_seq_te_id]\n",
    "    \n",
    "    # Nested insertion that has undergone fragmentation does not have 5' tsd\n",
    "    if frag == 100:\n",
    "        nested_line = gff_sel[:2] + [nest_subclas] + [new_end_1+1+tsd_5_len] + [new_start_2-tsd_3_len] + [\".\\t\" + strand + \"\\t.\"] + nest_name_in\n",
    "    else:\n",
    "        nested_line = gff_sel[:2] + [nest_subclas] + [new_end_1+1] + [new_start_2-tsd_3_len] + [\".\\t\" + strand + \"\\t.\"] + nest_name_in\n",
    "     \n",
    "    ori_name_2 = [gff_sel[8].replace(\";Name\",\"_2;Name\").replace(\";Clas\",\"_2;Clas\") + \";Cut_at=\" + str((pct_pos/100)) + \";Cut_by=\" + nest_name + \"_\" + nested_te_id]\n",
    "    ori_line_2 = gff_sel[:3] + [new_start_2] + [new_end_2 -1] + gff_sel[5:8] + ori_name_2\n",
    "    \n",
    "    n += 1\n",
    "    \n",
    "    #Update the entire gff list\n",
    "    index = j[0] + counter\n",
    "    new_gff.pop(index)\n",
    "    new_gff_aux = new_gff[:index]\n",
    "    new_gff_aux.append(ori_line_1)\n",
    "    new_gff_aux.append(nested_line)\n",
    "    new_gff_aux.append(ori_line_2)\n",
    "    new_gff_aux += new_gff[index:]\n",
    "    new_gff = new_gff_aux\n",
    "    new_gff = modify_coords(nest_len, index+3, new_gff)\n",
    "    counter += 2\n",
    "    \n",
    "    #Update the all inserted repeat seq dictionary\n",
    "    chr_id = gff_sel[0]\n",
    "    \n",
    "    ori_seq_name_old = isrt_te_dict[ori_seq_te_id].description\n",
    "    ori_seq_name_old_head = re.sub(\"-.*\", \"-\", ori_seq_name_old)\n",
    "    ori_seq_name_old_tail = re.sub(\".*;I\", \";I\", ori_seq_name_old)\n",
    "    ori_seq_name_old_tail = re.sub(\"]\", \"\", ori_seq_name_old_tail)\n",
    "    nest_note = \";Cut_at=\" + str((pct_pos/100)) + \";Cut_by=\" + nest_name + \"_\" + nested_te_id + \"]\"\n",
    "    ori_seq_name_new = ori_seq_name_old_head + str(new_end_2 -1) + ori_seq_name_old_tail + nest_note\n",
    "    \n",
    "    nested_seq_name = nest_name + \"_\" + nested_te_id + \"#\" + nest_superfam + \" [Location=\" + chr_id + \":\" + str(new_end_1+1+tsd_5_len) + \"-\" + str(new_start_2-tsd_3_len) + \";Identity=\" + str(nest_identity/100) + frag_note + \";Nest_in=\" + ori_seq_te_id + \"]\"\n",
    "    \n",
    "    isrt_te_dict[ori_seq_te_id].description = ori_seq_name_new\n",
    "    \n",
    "    #Create and update dictionary for nested TE seq\n",
    "    nest_te_dict[nested_te_id] = {'id': nested_seq_name, 'seq': new_nest_seq_str[tsd_5_len:(nest_len-tsd_3_len)]}\n",
    "    \n",
    "    #Update the genome sequence                \n",
    "    seq = str(genome[chr_id].seq)\n",
    "    new_seq = seq[:new_end_1] + new_nest_seq_str + seq[new_end_1:] \n",
    "    genome[chr_id].seq = new_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a8030d-cde0-42ab-a16d-6a3e3a16d668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7022d160-2599-47d2-9497-fa6cda68390c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f324c476-bede-4f34-8480-39c0f26c801a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944fa57a-cf05-41d5-8836-94aeeaebd870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35469661-d95f-4ef7-96b8-186302ba5f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b1625e-2b3a-440c-8176-5a274aaa560c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6547da52-034b-4103-8459-c14852288563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef3d64-c33a-40ff-a811-44b95829a2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e32cf7-6a45-4609-8669-50ef84a3cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate nested insertion\n",
    "genome, isrt_te_dict, nest_te_dict, new_gff = generate_genome_nests(repeats_dict, isrt_te, gff, genome)\n",
    "\n",
    "#Output new genome fasta, all inserted TE fasta, and GFF after nested insertion.\n",
    "print_genome_nest_data(genome, isrt_te_dict, nest_te_dict, new_gff, params_chr)\n",
    "repeats_dict = load_repeats_chr(params_chr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d2af87-abed-42f1-b465-6e386b83a662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e52a475-f88b-4f6f-9376-77b8589d07e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e57d4d-54ad-4801-b924-9a44761e8e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edffda54-cfa2-472e-947e-1e8cf021004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ##For custom genome with multiple chromosoms\n",
    "    ##Load parameters\n",
    "    params_chr = parse_custom_genome_yaml('config_custom_genome_DH_5_10.yml')\n",
    "    \n",
    "    seed = params_chr['seed']\n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "        \n",
    "    #Specify files created from previous step that generats non-overlapping insertions\n",
    "    file_prefix = str(params_chr['prefix'])\n",
    "    gff_file = \"./result/sim_\" + file_prefix +\"_genome/\" + file_prefix + \"_repeat_annotation_out.gff\"\n",
    "    fasta_file = \"./result/sim_\" + file_prefix +\"_genome/\" + file_prefix + \"_genome_sequence_out.fasta\"\n",
    "    isrt_te_fasta = \"./result/sim_\" + file_prefix +\"_genome/\" + file_prefix + \"_repeat_sequence_out.fasta\"\n",
    "    \n",
    "    #Load fasta files into dictionaries\n",
    "    genome = SeqIO.to_dict(SeqIO.parse(fasta_file,\"fasta\"))\n",
    "    isrt_te = load_isrt_te_fa(isrt_te_fasta)\n",
    "    \n",
    "    #Load non-redundant TE library and the gff file containing all TE insertions\n",
    "    repeats_dict = load_repeats_chr(params_chr)\n",
    "    gff = load_gff(gff_file)\n",
    "    \n",
    "    #Generate nested insertion\n",
    "    genome, isrt_te_dict, nest_te_dict, new_gff = generate_genome_nests(repeats_dict, isrt_te, gff, genome)\n",
    "    \n",
    "    #Output new genome fasta, all inserted TE fasta, and GFF after nested insertion.\n",
    "    print_genome_nest_data(genome, isrt_te_dict, nest_te_dict, new_gff, params_chr)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169abb45-31e5-48b7-919a-84ae3f3daf9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4deb877-30b1-4ec9-855e-5fdc24fb4c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758b4a8f-edd9-470c-9809-1efe00bb96fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0800864-a43f-4189-a67c-6fc3b3234698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894129e6-69f2-4b5b-b43d-b9e23eb7b674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b97fb-061e-4ee6-8d85-e3d47697782d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PFR Python3-3.9.13",
   "language": "python",
   "name": "pfr-python3-3.9.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
